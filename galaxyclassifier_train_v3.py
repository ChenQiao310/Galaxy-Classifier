# -*- coding: utf-8 -*-
"""galaxyClassifier_train_v3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OPWMUb7t4ybqsvNDCO57_2q6S8c0iVKI

Import google drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""Unzip files"""

!unzip /content/drive/MyDrive/input.zipyes

import os
import math
import random
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from random import sample
import cv2 as cv
import imutils
from skimage.transform import resize
from sklearn.model_selection import train_test_split
from tqdm import tqdm

"""Read csv file & Generate labels"""

labels = pd.read_csv('/content/drive/MyDrive/category.csv')

"""Train/Test Split"""

labels_train, labels_test = train_test_split(labels, test_size=.2)
labels_test.to_csv('test_true.csv', index=False)

print('Split traning labels: ')
labels_train.shape, labels_test.shape

"""One_hot Encoding"""

one_hot_train = pd.get_dummies(labels_train, columns = ['Category'])
one_hot_test = pd.get_dummies(labels_test, columns = ['Category'])
#print(labels_train)
#print(one_hot_train)
#print(labels_test)
#print(one_hot_test)
#one_hot_test.to_csv('test_true_oneHot.csv', index=False)

labels_train["Category"].value_counts()

"""Preprocess the images"""

SIZE = (224,224)

def preprocess_image(img_path):
    img = plt.imread(img_path)
    img = tf.image.resize_with_crop_or_pad(img, SIZE[0], SIZE[1])
    img = img/255
    return img

def preprocess_images(labels):
    data = labels.values
    img_ids = data[:,0].astype(int).astype(str)
    images = []
    
    for i in tqdm(img_ids):
        img = preprocess_image('/content/input/training/'+i+'.jpg')
        images.append(img)
        
    return images

train_imgs = preprocess_images(one_hot_train)
test_imgs = preprocess_images(one_hot_test)
labels_all = labels_train

"""Image data augmentation preparation"""

class_1 = labels_train[labels_train['Category'] == 1]
class_2 = labels_train[labels_train['Category'] == 2]
class_3 = labels_train[labels_train['Category'] == 3]

def rotate_image(img_path, angle):
  img = plt.imread(img_path)
  img = imutils.rotate(img, angle)
  img = tf.image.resize_with_crop_or_pad(img, SIZE[0], SIZE[1])
  img = img/255
  return img

def rotate_images(labels):
  data = labels.values
  img_ids = data[:,0].astype(int).astype(str)
    
  for i in tqdm(img_ids):
    angle = 90*random.randint(1, 4)+random.randint(-20, 20)
    img = rotate_image('/content/input/training/'+i+'.jpg', angle)
    train_imgs.append(img)
        
  images = train_imgs
  return images

"""Augmentation of all minority classes"""

labels_all = pd.concat([labels_train, class_1, class_2, class_3], axis=0)
one_hot_rotate = pd.get_dummies(labels_all, columns = ['Category'])
one_hot_rotate = one_hot_rotate[len(labels_train):]
labels_train = labels_all

train_imgs = rotate_images(one_hot_rotate)
one_hot_train = pd.concat([one_hot_train, one_hot_rotate], axis=0)

"""Augmentation of classes with lowest frequency"""

for i in range(4):
  labels_all = pd.concat([labels_train, class_3], axis=0)
  one_hot_rotate = pd.get_dummies(labels_all, columns = ['Category'])
  one_hot_rotate = one_hot_rotate[len(labels_train):]
  labels_train = labels_all
  
  train_imgs = rotate_images(one_hot_rotate)
  one_hot_train = pd.concat([one_hot_train, one_hot_rotate], axis=0)

"""Pie chart of current training set"""

labels_train["Category"].value_counts().plot(kind='pie')

"""Pie chart of test set"""

labels_test["Category"].value_counts().plot(kind='pie')

"""Set labels and array of images"""

train_labels = one_hot_train.values[:,1:]
train_imgs = np.array(train_imgs)
test_labels = one_hot_test.values[:,1:]
test_imgs = np.array(test_imgs)

"""Shuffle Training set"""

random.seed(0)
random.shuffle(train_labels)
random.seed(0)
random.shuffle(train_imgs)

"""Build CNN model"""

import keras,os
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D , Flatten
from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, GlobalMaxPooling2D
from keras import layers, metrics, losses, callbacks, regularizers
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras import backend as K
from keras import regularizers
from keras.preprocessing.image import ImageDataGenerator
#from keras_tuner.engine.hyperparameters import HyperParameters
#from kerastuner.tuners import RandomSearch, Hyperband
#from tensorflow.keras.optimizers import SGD, Adam

# My CNN model
model = Sequential()
#, kernel_initializer=tf.keras.initializers.HeNormal()
model.add(Conv2D(input_shape=(SIZE[0],SIZE[1],3),filters=224,kernel_size=(3,3), activation="relu", padding="same")) 
#model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
#model.add(Dropout(0.25))

model.add(Conv2D(filters=32, kernel_size=(3,3), activation="relu", ))
#model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
#model.add(Dropout(0.15))

model.add(Conv2D(filters=64, kernel_size=(3,3), activation="relu"))
#model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
#model.add(Dropout(0.2))

model.add(Conv2D(filters=192, kernel_size=(3,3), activation="relu"))
#model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(filters=128, kernel_size=(5,5), activation="relu"))
#model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())
model.add(Dense(units=256,activation="relu"))
model.add(Dense(units=4, activation="softmax"))

model.compile(loss='categorical_crossentropy',
              optimizer=tf.keras.optimizers.Adam(learning_rate=8e-4), #optimizer: RMSprop, SGD, tf.keras.optimizers.Adam(learning_rate=1e-3)
              metrics=[tf.keras.metrics.Precision()])

model.summary()

"""Train the model"""

datagen = ImageDataGenerator(
                featurewise_center = False,             
                samplewise_center  = False,             
                featurewise_std_normalization = False,  
                samplewise_std_normalization  = False,  
                zca_whitening = False,                  
                rotation_range = 20,                    
                width_shift_range  = 0.2,               
                height_shift_range = 0.2,               
                horizontal_flip = True,                 
                vertical_flip = False)                  

datagen.fit(train_imgs)

# train My CNN model
batch_size = 32
hist = model.fit(datagen.flow(train_imgs, train_labels,batch_size = batch_size),epochs=25,validation_data=(test_imgs, test_labels))

model.save("galaxyClassifier-model.h5")